[["index.html", "DLL 2021, R section 1 Workshop introduction 1.1 Workshop goals 1.2 Structure and resources 1.3 Workshop expectations", " DLL 2021, R section mesako Margaret Samson Zac darachm Typeset on 2021-06-07 1 Workshop introduction 1.1 Workshop goals This short 3-day course aims to give you a basic framework so you can work with someone effectively on a research project using R. This framework includes getting you oriented with basic skills (e.g. using RStudio, documenting your process with R Markdown, basic data analysis and visualization) and empowering you to figure out how to accomplish research-related tasks in R. 1.2 Structure and resources 1.2.1 This syllabus and videos We developed this website/document for your reference, as a living textbook and collection of “slides” and code snippets. We have also made short teaching videos uploaded on Youtube that are embedded where appropriate on this site. These mini-lectures are intended to complement the text for those with different learning preferences. You will be expected to progress through this website during asynchronous work time in this 3-day period. During synchronous meetings, you should plan to work directly with your peers and us on focused tasks. We will also be there to help with confusing or challenging topics that you want to discuss with someone live. 1.2.2 Slack channel While you are working in asynchronous sessions, or if you just need help during the program, there is a Slack channel available where you can go for ideas/help. The channel is called #codingtroubleshooting and should be accessible to you on the SSRP Slack server. 1.3 Workshop expectations Be respectful and compassionate. Teach one another, learn from one another. Aim for productive struggle. You will learn best if you make a good faith effort before seeking help. However, you should always seek help if you feel truly stuck. Create your own sense of challenge. Pick activities that you will learn and grow from. If you don’t find something challenging, make it challenging for yourself. "],["day-3-intoduction-to-r.html", "2 Day 3 - intoduction to R 2.1 Navigating Rstudio 2.2 Using Rmds 2.3 Getting started in R 2.4 Working with vectors 2.5 Working with dataframes", " 2 Day 3 - intoduction to R Learning Goals: By the end of today’s session, students will be able to: Navigate the RStudio environment and move between the different panels. Open, save, and run an Rmd (R Markdown) file within RStudio. Apply internet searches, help functions, and documentation to learn to use the appropriate functions. Assign and manipulate variables within the current environment/session in R. Create, modify, and access into a vector (an ordered grouping of elements). Create, modify, and access into a dataframe (an ordered two-dimensional grouping of elements with rows and columns). Apply existing functions to accomplish a specific task in R. 2.1 Navigating Rstudio Rstudio x &lt;- 1 x ## [1] 1 2.2 Using Rmds Approach: an Rmd tutorial with a simple dataset in R. This is meant to be a motivation for what one can do in R, not necessarily understanding syntax of every function/operation used Topics/Exercises: Present a conceptual framework for a pipeline - more of a tutorial Use an Rmd file for this and introduce how to navigate the Rmd file Scholars can execute a given Rmd Scholars can modify a given Rmd Scholars know what the major pieces of an Rmd are (code and not code) Scholars know about caching and arguments for code chunks Scholars know how to make their own new Rmd file and run it Load a simple dataset in R - the iris dataset, peek at the table with head, summarize the columns, and make a scatter plot with base R. This introduces several topics Requires: interacting with R, calling functions, and saving variables 2.3 Getting started in R Let’s get started programming in R! Our goal is to be able to interact with datasets like the built-in iris dataset in R. By the end of today, we aim to be able to pull out information from this dataset and modify it using R programming. head(iris, n = 10) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa 2.3.1 Getting help in R If you run into any error while using R, it is a great idea to look up your error message in Google and read through forum posts on StackOverflow. You may find it also helps to know more about your session info such as the version of R you are using, and what packages you have currently loaded. sessionInfo() You can look up what functions do using either a question mark ? or the help function. ?rm help(rm) You can try running the following command to look up variables that load in with base R or packages that we will use. For example, you can use the help function to read more details about the iris dataset. ?iris 2.3.2 Using variables and data types Variables are a short-hand name or label that stores a piece of data. We can save information into variables and then call them by name (invoke the variable) to use that information when needed. You can assign variables using the = or &lt;- operators. We will use the &lt;- operator exclusively going forward. save.num &lt;- 7 save.num ## [1] 7 Here I have chosen the name save.num but you can give it a different name. Note that variable names must with a letter and cannot contain special characters. Variables are mutable: you can overwrite the saved value of a variable with another value. save.num &lt;- 10 save.num ## [1] 10 You can see that save.num does not remember the value 7 anymore and instead returns 10. Variables can be saved as other values such as character strings or boolean values (TRUE or FALSE). These are examples of other datatypes in R. save.string &lt;- &quot;hello&quot; save.bool &lt;- TRUE You can check what variables you have assigned in your current working environment using the ls function. Try running ?ls to learn more about this function! ls() ## [1] &quot;save.bool&quot; &quot;save.num&quot; &quot;save.string&quot; You can also remove saved variables using the rm function. rm(save.num) ls() ## [1] &quot;save.bool&quot; &quot;save.string&quot; You will notice that our session no longer remembers save.num. If you tried to call save.num after it was removed, you would get an error message in R. 2.3.3 Using functions We have already shared several functions with you, including the help function, the ls function, and the rm function. Even the command sessionInfo is an example of a function in R! Functions can be recognized by a string (letters) followed by parentheses (). Functions may take information inside the parentheses that are called arguments. ?help When you look at documentation for the help function, you will notice that there are many things you can provide inside the parentheses. The documentation section called “Arguments” describes one necessary input for help called topic that must be provided inside the parentheses. Arguments are often named and described in the documentation. When you provide an argument to a function, you can provide it by name explicitly or just let R figure it out based on the order you give it. help(topic = iris) help(iris) In the second line, we provide only one input iris and R assumes that we intend for topic = iris as the argument. One function we will use often is the c function which can be used to create a vector or ordered collection of pieces of information. ?c If you look up the documentation for the c function, you will notice that it accepts ... arguments. This can be confusing but it often means that it accepts multiple arguments, more than can be named or described. This makes sense for the c function because it will accept as many inputs as you give it, the number does not need to be consistent. save.data &lt;- c(1, 4, 6, 2, 3, 8, NA) Functions generally take the arguments in the parentheses as an input and then produce some output. A clear example of this is using the mean function. ?mean As implied, the mean function will take a grouping of numbers and return the mean or the average. mean(save.data) ## [1] NA However, here we ran into an issue because one of the elements in our initial vector save.data is NA. NA means “not available” or in other words the data is missing. This is not the same as being zero. So R is not sure how to calculate the mean since that last element is essentially a question mark. We can make use of an additional argument that the mean function takes, namely the na.rm argument. This argument functions more like a setting, where you can provide a flag (i.e. TRUE or FALSE) or a distinct option (e.g. top, bottom, left, or right) that modifies how it produces the output. This argument has a default that is shown in the “Usage” section of the documentation. We are going to change that setting. mean(save.data, na.rm = TRUE) ## [1] 4 Now you can see that R runs the function and decides to leave out or ignore the NA value and is able to return an average based on the other values in save.data. 2.4 Working with vectors The power of using programming like R is to be able to process, analyze, and visualize large sets of data. We will build our way up to thinking about tabular data like that in the iris dataset starting first with vectors. Remember that you can create vectors (an ordered list of elements) by combining elements with the c function. 2.4.1 Building vectors Let us pretend that we measured and recorded the resting heart rates of several patients. We will create these vectors and assign them to some variables. heart.rates &lt;- c(78, 68, 95, 82, 69, 63, 86, 74, 64, 62) more.heart.rates &lt;- c(86, 79, 64, 74, 80) heart.rates ## [1] 78 68 95 82 69 63 86 74 64 62 more.heart.rates ## [1] 86 79 64 74 80 We have used the c function to combine several individual elements that we typed out, but you can combine vectors together to make an even bigger vector. all.heart.rates &lt;- c(heart.rates, more.heart.rates) all.heart.rates ## [1] 78 68 95 82 69 63 86 74 64 62 86 79 64 74 80 Vectors can contain different datatypes besides numbers. We can also provide several character strings in a vector, like the names of our patients. patient.names &lt;- c(&quot;oakley&quot;, &quot;rashmi&quot;, &quot;kiran&quot;, &quot;eun&quot;, &quot;sasha&quot;, &quot;mattie&quot;) However, note that vectors cannot handle multiple different datatypes at once. If you try to provide a vector with multiple datatypes: mixed.data &lt;- c(&quot;oakley&quot;, 18, TRUE, &quot;eun&quot;, NA, 50) mixed.data ## [1] &quot;oakley&quot; &quot;18&quot; &quot;TRUE&quot; &quot;eun&quot; NA &quot;50&quot; You can see this displays these elements enclosed in quotes, to indicate that R has converted them all to the same datatype (i.e. character string). There are several helpful functions and an operator that can speed up your ability to generate vectors. The : operator quickly creates a numeric vector for a range of values. 1:4 ## [1] 1 2 3 4 The seq function can help you quickly create numeric vectors. The rep function can be used to build either numeric or character string vectors. Reading the documentation will tell you which arguments these functions take. ?seq ?rep Here are examples of how they can be used: z &lt;- seq(0, 100, by = 20) z ## [1] 0 20 40 60 80 100 z &lt;- rep(&quot;A&quot;, times = 5) z ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; 2.4.2 Indexing and subsetting vectors Indexing is a way to access into a vector (or a matrix or a data frame) and pull out certain elements. There are multiple ways to index into a vector, one of the easiest ways is to pull out an element based on its order/position in the grouping (its index). We use [] immediately after the name of the grouping (in this case a vector) to access into it. all.heart.rates[2] # pull out second heart rate measurement ## [1] 68 patient.names[3] # pull out third patient name ## [1] &quot;kiran&quot; You can also pull out several elements at a time. To do this, you provide a vector of numeric values within the parentheses. patient.names[2:3] # pull out 2nd and 3rd patient name ## [1] &quot;rashmi&quot; &quot;kiran&quot; patient.names[c(1, 3)] # pull out 1st and 3rd patient name ## [1] &quot;oakley&quot; &quot;kiran&quot; You can remove elements of a vector by using the same syntax of indexing, but instead put a negative sign in front of the index number. patient.names[-1] ## [1] &quot;rashmi&quot; &quot;kiran&quot; &quot;eun&quot; &quot;sasha&quot; &quot;mattie&quot; There are times where we will want to pull out certain elements of a vector using something other than the position. What if we do not know where they are located, especially if the vector is very long? 2.4.3 Using logic and logicals You can also access elements in a vector that meet certain criteria using what we will call conditional logic. Logic will be a recurring idea in programming. Logic looks like evaluating whether something meets your criteria and evaluating it as either TRUE or FALSE (remember these words are special and represent a logical datatype). Let’s explore what it looks like to evaluate a statement. save.num &lt;- 7 save.num &lt; 8 ## [1] TRUE save.num &gt; 8 ## [1] FALSE save.num != 8 ## [1] TRUE save.num == 8 ## [1] FALSE You can use the standard comparison operators like &gt; or &lt; to check greater than or less than. You can also use == to check for equality or != to check that values are not equal. We can do the same thing with vectors, and it will be performed in a vectorized manner. That is, by default, R will evaluate each element in the vector to see if it meets the criteria. For example, we can evaluate each heart rate in our original vector to see whether or not the value is less than 80. all.heart.rates &lt; 80 ## [1] TRUE TRUE FALSE FALSE TRUE TRUE FALSE TRUE TRUE TRUE FALSE TRUE ## [13] TRUE TRUE FALSE This series of flags with TRUE and FALSE can be used to access into a vector and will only return the elements where there is a TRUE. all.heart.rates[all.heart.rates &lt; 80] ## [1] 78 68 69 63 74 64 62 79 64 74 In the context of bigger data analysis, we can use conditional logic to make choices between executing different sets of code. You can pair these conditional statements with an if/else statement that breaks up the code and only executes parts of the code where conditions are met. test.num &lt;- 30 if (test.num &lt; 10) { print(&quot;small&quot;) } else { print(&quot;big&quot;) } ## [1] &quot;big&quot; Here, the code within the brackets only runs if the condition is met. Since the statement next to the if evaluates as FALSE, it then only executes the code within the brackets of the else clause. 2.4.4 Modifying vectors Let’s look into how we change an existing vector. We can save data into a vector, access this data, but we will likely want to process it too! We can investigate an unknown vector using several functions, like the length function. As the name implies, it returns how many elements your vector contains. x &lt;- c(1, 3, 2) y &lt;- c(5, 4, 6) length(x) ## [1] 3 length(y) ## [1] 3 Let’s try modifying the values in an existing vector. Note that when you try to add values to a vector, it can be done in a pairwise manner or uniformly across the entire vector. Let’s see what it looks like when we have pairwise addition of two vectors of the same length. x + y ## [1] 6 7 8 Here, you can see that the first element of x is added to the first element of y to create a new value in the first element. The same happens with the second element and so forth. You can perform mathematical operations on an entire numeric vector all at once. Here we take the vector of our heart rate data and add 1 to it, which will add 1 to each individual element in the entire vector. all.heart.rates + 1 ## [1] 79 69 96 83 70 64 87 75 65 63 87 80 65 75 81 This is another example of a vectorized operation, where we perform a step automatically to all items in a collection of items (e.g. a vector). This works with operators like + or -, but also with certain functions. ?log For example, the log function calculates the log value of a number. If you provide it with a vector, it will do that calculation for each element, returning a vector of the same length. log(all.heart.rates) ## [1] 4.356709 4.219508 4.553877 4.406719 4.234107 4.143135 4.454347 4.304065 ## [9] 4.158883 4.127134 4.454347 4.369448 4.158883 4.304065 4.382027 This demonstrates how one can quickly transform or scale values in a dataset. For example, you might have taken the temperature of an experiment in Fahrenheit and using the power of vectorization, you can apply the same arithmetic steps to all of your measurements simultaneously to get the values in Celsius. Here is an additional example using the signif function, which returns your numeric values with the number of significant digits that you specify. ?signif Here we can specify one significant figure to get only the tens digit (or the hundreds digit if there is a value over 100). signif(all.heart.rates, digits = 1) ## [1] 80 70 100 80 70 60 90 70 60 60 90 80 60 70 80 Any of these results can also be saved into a new vector name (e.g. heart.rates2) or we can save over the original variable name if we are fixing the data. 2.5 Working with dataframes We can now work our way from vectors to dataframes. The most common data format we will deal with in research is a dataframe format. A dataframe has data is stored in a tabular format with the rows generally referring to individual measurements (single patients, samples, cells, etc.) and the columns referring to parameters (genes, proteins, etc.) measured in each individual. Essentially a dataframe can be thought of a bunch of vectors lined up in columns or lined up in rows. We work with a dataframe instead of a matrix (another datatype in R) because dataframes can tolerate different datatypes in the same table. As seen below, a matrix will easily accept data all of the same datatype, but do unexpected things when you provide multiple datatypes. matrix1 &lt;- matrix(data = c(1, 2, 3, 4, 5, 6, 7, 8, 9), nrow = 3, ncol = 3) matrix1 ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 matrix2 &lt;- matrix(data = c(1, &quot;apple&quot;, 3, TRUE, &quot;cat&quot;, 6, 7, NA, FALSE), nrow = 3, ncol = 3) matrix2 ## [,1] [,2] [,3] ## [1,] &quot;1&quot; &quot;TRUE&quot; &quot;7&quot; ## [2,] &quot;apple&quot; &quot;cat&quot; NA ## [3,] &quot;3&quot; &quot;6&quot; &quot;FALSE&quot; Now matrix1 looks normal, but you may notice that matrix2 has quotation marks around its elements, including the numbers and the TRUE/FALSE values. This means these elements are all being treated like character strings because we included elements like apple and R wants them to be one consistent type. While we are working mainly with dataframes, tibbles will pop up as we work in tidyverse. Tibbles are very similar to dataframes in their ability to handle different data types across their different columns. You can think of them as very similar entities. We will first explore the built-in iris dataset. If you look up its documentation, you will notice that it is described as a dataframe and does contain both numeric values and character strings for the names of species. ?iris For the sake of this exercise, we will assign a new variable called iris.temp that is a shorter version of the original dataset. The head function returns just the first few rows and here we use an argument to request the first 10. iris.temp &lt;- head(iris, n = 10) iris.temp ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa 2.5.1 Indexing and subsetting dataframes You can index into a dataframe and pull out one or more cells within the dataframe. Note that we are providing two coordinates to explain which row (the first number before the comma) and which column (the second number after the comma) to find the exact element (or cell in the table). iris.temp[1, 3] ## [1] 1.4 You can pull out multiple elements at a time, specifying which row and column they reside in. iris.temp[c(1, 2), c(2, 3)] # gives us the 2nd and 3rd columns of the 1st and 2nd rows ## Sepal.Width Petal.Length ## 1 3.5 1.4 ## 2 3.0 1.4 iris.temp[1:3, 3:5] # gives us the 3rd through 5th columns of the 1st through 3rd rows ## Petal.Length Petal.Width Species ## 1 1.4 0.2 setosa ## 2 1.4 0.2 setosa ## 3 1.3 0.2 setosa If you provide the row and not the column, or vice versa, by default R will pull out all of the available columns and rows respectively. iris.temp[1:2, ] # pulls out the first two rows and all columns ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa iris.temp[, 1:2] # pulls out the first two columns and all rows ## Sepal.Length Sepal.Width ## 1 5.1 3.5 ## 2 4.9 3.0 ## 3 4.7 3.2 ## 4 4.6 3.1 ## 5 5.0 3.6 ## 6 5.4 3.9 ## 7 4.6 3.4 ## 8 5.0 3.4 ## 9 4.4 2.9 ## 10 4.9 3.1 It’s possible to also remove elements in a dataframe using the negative sign. iris.temp2 &lt;- iris.temp[-c(1, 3), ] # removes the first and third rows head(iris.temp) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa head(iris.temp2) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 2 4.9 3.0 1.4 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa We saved the shorter dataset into a new variable and when we preview iris.temp against iris.temp2 you may be able to see the missing rows. 2.5.2 Exploring dataframes When you are first presented with a dataframe, for example data that was collected in your research lab that you are tasked with analyzing, you will want to learn more about it. There are a few different functions you can use to investigate a dataframe, the size of it, and other aspects. The dim function, short for dimensions, returns the number of rows and columns. dim(iris) ## [1] 150 5 dim(iris.temp) ## [1] 10 5 This shows you that iris.temp is in fact just the first 10 rows of iris. You can use the following functions: str for structure, colnames for column names, and summary to investigate aspects of a given dataset. colnames(iris) ## [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; &quot;Species&quot; str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## The str function reveals that the iris dataframe contains different data types. Specifcally, it mostly contains columns of numbers as well as a column of factors or categorical data referring to which species the iris belonged to. The summary function tries to tell us more info about each column. For numerical data, it summarizes the min and max values, the quartiles, and the center values (e.g. median or mean). For categorical data like the Species column, this function shows how many rows belong to each category. We can try to look at the beginning of a specific column in this dataset to get a better understanding for it. Dataframes that have names for their columns allow you to index into the columns specifically by name using the $ operator as shown below. head(iris$Species) ## [1] setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica Remember the head function lets us preview a longer set of data, either showing the first few elements of a vector or the first few rows of a dataframe. 2.5.3 Building and modifying dataframes We can also generate our own dataframes from vectors that we put together into a table. Revisiting our heart rate measurement example, let’s build a dataframe of patient data. patient.data &lt;- data.frame(name = c(&quot;oakley&quot;, &quot;rashmi&quot;, &quot;kiran&quot;), heart_rate = c(78, 68, 95), disease_status = c(FALSE, FALSE, TRUE)) patient.data ## name heart_rate disease_status ## 1 oakley 78 FALSE ## 2 rashmi 68 FALSE ## 3 kiran 95 TRUE We can inspect the dataframe we have created using the same functions. str(patient.data) ## &#39;data.frame&#39;: 3 obs. of 3 variables: ## $ name : chr &quot;oakley&quot; &quot;rashmi&quot; &quot;kiran&quot; ## $ heart_rate : num 78 68 95 ## $ disease_status: logi FALSE FALSE TRUE summary(patient.data) ## name heart_rate disease_status ## Length:3 Min. :68.00 Mode :logical ## Class :character 1st Qu.:73.00 FALSE:2 ## Mode :character Median :78.00 TRUE :1 ## Mean :80.33 ## 3rd Qu.:86.50 ## Max. :95.00 You can add new rows and columns using the rbind and cbind functions. Let’s pretend that we had collected additional information about our patients, such as their self-reported gender. We can add this as a new column (cbind short for bind column). patient.data &lt;- cbind(patient.data, gender = c(&quot;M&quot;, &quot;F&quot;, NA)) patient.data ## name heart_rate disease_status gender ## 1 oakley 78 FALSE M ## 2 rashmi 68 FALSE F ## 3 kiran 95 TRUE &lt;NA&gt; You can merge two dataframes together using the rbind function assuming that their columns match up correctly. Let’s pretend that we had another day at the clinic and collected additional patient measurements. more.patients &lt;- data.frame(name = c(&quot;eun&quot;, &quot;sasha&quot;, &quot;mattie&quot;), heart_rate = c(86, 79, 64), disease_status = c(TRUE, TRUE, FALSE), gender = c(NA, &quot;M&quot;, &quot;F&quot;)) more.patients ## name heart_rate disease_status gender ## 1 eun 86 TRUE &lt;NA&gt; ## 2 sasha 79 TRUE M ## 3 mattie 64 FALSE F Let’s use rbind, short for binding rows, to add these additional rows to the bottom of our first dataframe patient.data. all.patients &lt;- rbind(patient.data, more.patients) all.patients ## name heart_rate disease_status gender ## 1 oakley 78 FALSE M ## 2 rashmi 68 FALSE F ## 3 kiran 95 TRUE &lt;NA&gt; ## 4 eun 86 TRUE &lt;NA&gt; ## 5 sasha 79 TRUE M ## 6 mattie 64 FALSE F You can also remove rows and columns using the trick with a negative index. patient.data[, -1] # removes first column ## heart_rate disease_status gender ## 1 78 FALSE M ## 2 68 FALSE F ## 3 95 TRUE &lt;NA&gt; patient.data[-1, ] # removes first row ## name heart_rate disease_status gender ## 2 rashmi 68 FALSE F ## 3 kiran 95 TRUE &lt;NA&gt; 2.5.4 Handling datatypes in dataframes One of the great strengths of a dataframe is that it can handle each column containing different datatypes. Our patient data has columns of character strings, logicals, and numerical values. However, you should take care that sometimes unexpected behavior may arise when a column in your dataframe is one datatype and you add data that is not compatible with that datatype. Remember that vectors can only contain one datatype at a time? Each column in the dataframe is essentially a vector. We briefly discussed factors as categorical variables. Let’s pretend that for our analysis we wanted to treat gender as a categorical variable. Factors are a special datatype that deals with categorical data and can be handy for certain manipulations or visualizations. To do this, we can coerce data into a different datatype using functions like as.function. head(all.patients$gender) ## [1] &quot;M&quot; &quot;F&quot; NA NA &quot;M&quot; &quot;F&quot; all.patients$gender &lt;- as.factor(all.patients$gender) head(all.patients$gender) ## [1] M F &lt;NA&gt; &lt;NA&gt; M F ## Levels: F M This vector of factors shows which category each element belongs to, and then summarizes what the possible categories are down at the bottom where it prints the Levels of this factor. This can cause issues if we introduce data that does not match these categories. Let’s try adding a new patient’s data. all.patients &lt;- rbind(all.patients, c(name = &quot;lupe&quot;, heart_rate = 72, disease_status = FALSE, gender = &quot;NB&quot;)) ## Warning in `[&lt;-.factor`(`*tmp*`, ri, value = &quot;NB&quot;): invalid factor level, NA ## generated all.patients ## name heart_rate disease_status gender ## 1 oakley 78 FALSE M ## 2 rashmi 68 FALSE F ## 3 kiran 95 TRUE &lt;NA&gt; ## 4 eun 86 TRUE &lt;NA&gt; ## 5 sasha 79 TRUE M ## 6 mattie 64 FALSE F ## 7 lupe 72 FALSE &lt;NA&gt; What has happened with this new addition? If you tried to add a new patient to the dataframe that had a gender that wasn’t already represented in the data, chances are you had a warning and that gender was turned to NA. all.patients$gender ## [1] M F &lt;NA&gt; &lt;NA&gt; M F &lt;NA&gt; ## Levels: F M Once a factor is created, it doesn’t let you easily add new categories that were not in the original set. We will not get issues though if we add a new patient whose gender is represented as one of the levels in our gender factor. all.patients &lt;- rbind(all.patients, c(name = &quot;chihiro&quot;, heart_rate = 101, disease_status = TRUE, gender = &quot;M&quot;)) all.patients$gender ## [1] M F &lt;NA&gt; &lt;NA&gt; M F &lt;NA&gt; M ## Levels: F M So how do we fix this? The easiest way around this is to treat the column as characters instead of as factors. all.patients$gender &lt;- as.character(all.patients$gender) all.patients &lt;- rbind(all.patients, c(name = &quot;ayodele&quot;, heart_rate = 101, disease_status = TRUE, gender = &quot;NB&quot;)) all.patients$gender ## [1] &quot;M&quot; &quot;F&quot; NA NA &quot;M&quot; &quot;F&quot; NA &quot;M&quot; &quot;NB&quot; There will be times that we want to treat certain columns in our data as a factor, but take care that you add compatible data to each column of your existing dataset. "],["day-4-tidyverse-and-visualizations.html", "3 Day 4 - tidyverse and visualizations 3.1 Reading and processing data 3.2 Using tidyverse 3.3 Using tidyverse 3.4 Making plots with ggplot2 3.5 Making scientific figures 3.6 Applying basic stats", " 3 Day 4 - tidyverse and visualizations Learning Goals: By the end of today’s session, students will be able to: Read in and process data starting from a local saved file Transform, scale, filter, and convert values within a dataset Descibe the roles of data, aesthetics, and geoms in ggplot functions. Choose the correct aesthetics and alter the geom parameters for a scatter plot, histogram, or box plot. Layer multiple geometries in a single plot. Customize plot scales, titles, subtitles, themes, fonts, layout, and orientation. Apply a facet to a plot. Save a ggplot to a file. 3.1 Reading and processing data find a file-reading function, know of a few use read.csv to read a file and save it as a variable, and tune some arguments irisz &lt;- read.csv(&quot;data/iris.csv&quot;) head(irisz) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Location ## 1 5.1 3.5 1.4 0.2 setosa Korea ## 2 4.9 3 1.4 0.2 setosa China ## 3 4.7 3.2 1.3 0.2 setosa Korea ## 4 4.6 3.1 1.5 0.2 setosa China ## 5 5 3.6 1.4 0.2 setosa China ## 6 5.4 1.7 0.4 setosa Canada head(irisz$Species) ## [1] &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; Settings for read.csv irisz &lt;- read.csv(&quot;data/iris.csv&quot;, stringsAsFactors = TRUE) head(irisz$Species) ## [1] setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica head(irisz$Location) ## [1] Korea China Korea China China Canada ## Levels: Canada China Japan Korea Russia USA irisz &lt;- read.csv(&quot;data/iris.csv&quot;, col.names = c(&quot;sep_len&quot;, &quot;sep_wid&quot;, &quot;pet_len&quot;, &quot;pet_wid&quot;, &quot;species&quot;, &quot;loc&quot;)) head(irisz) ## sep_len sep_wid pet_len pet_wid species loc ## 1 5.1 3.5 1.4 0.2 setosa Korea ## 2 4.9 3 1.4 0.2 setosa China ## 3 4.7 3.2 1.3 0.2 setosa Korea ## 4 4.6 3.1 1.5 0.2 setosa China ## 5 5 3.6 1.4 0.2 setosa China ## 6 5.4 1.7 0.4 setosa Canada important to preview data and look for issues, and have some strategies/functions to do this Examining Data str(irisz) ## &#39;data.frame&#39;: 150 obs. of 6 variables: ## $ sep_len: chr &quot;5.1&quot; &quot;4.9&quot; &quot;4.7&quot; &quot;4.6&quot; ... ## $ sep_wid: chr &quot;3.5&quot; &quot;3&quot; &quot;3.2&quot; &quot;3.1&quot; ... ## $ pet_len: chr &quot;1.4&quot; &quot;1.4&quot; &quot;1.3&quot; &quot;1.5&quot; ... ## $ pet_wid: chr &quot;0.2&quot; &quot;0.2&quot; &quot;0.2&quot; &quot;0.2&quot; ... ## $ species: chr &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... ## $ loc : chr &quot;Korea&quot; &quot;China&quot; &quot;Korea&quot; &quot;China&quot; ... summary(irisz) ## sep_len sep_wid pet_len pet_wid ## Length:150 Length:150 Length:150 Length:150 ## Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character ## species loc ## Length:150 Length:150 ## Class :character Class :character ## Mode :character Mode :character unique(irisz$sep_len) ## [1] &quot;5.1&quot; &quot;4.9&quot; &quot;4.7&quot; &quot;4.6&quot; &quot;5&quot; &quot;5.4&quot; &quot;4.4&quot; &quot;4.8&quot; &quot;4.3&quot; &quot;5.8&quot; &quot;5.7&quot; &quot;5.2&quot; ## [13] &quot;5.5&quot; &quot;4.5&quot; &quot;n/a&quot; &quot;5.3&quot; &quot;7&quot; &quot;6.4&quot; &quot;6.9&quot; &quot;6.5&quot; &quot;6.3&quot; &quot;6.6&quot; &quot;5.9&quot; &quot;6&quot; ## [25] &quot;6.1&quot; &quot;5.6&quot; &quot;6.7&quot; &quot;6.2&quot; &quot;6.8&quot; &quot;7.1&quot; &quot;7.6&quot; &quot; &quot; &quot;7.2&quot; &quot;7.7&quot; &quot;7.4&quot; &quot;7.9&quot; what NAs are, some strategies to deal with these Handling Missing Data irisz &lt;- read.csv(&quot;data/iris.csv&quot;, na.strings = c(&quot;&quot;, &quot;n/a&quot;), stringsAsFactors = TRUE) head(irisz) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Location ## 1 5.1 3.5 1.4 0.2 setosa Korea ## 2 4.9 3.0 1.4 0.2 setosa China ## 3 4.7 3.2 1.3 0.2 setosa Korea ## 4 4.6 3.1 1.5 0.2 setosa China ## 5 5.0 3.6 1.4 0.2 setosa China ## 6 5.4 NA 1.7 0.4 setosa Canada str(irisz) ## &#39;data.frame&#39;: 150 obs. of 6 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 NA 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 NA 1 1 ... ## $ Location : Factor w/ 6 levels &quot;Canada&quot;,&quot;China&quot;,..: 4 2 4 2 2 1 2 2 5 3 ... summary(irisz) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :0.350 Min. :1.000 Min. : 0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.550 1st Qu.: 0.300 ## Median :5.800 Median :3.000 Median :4.300 Median : 1.300 ## Mean :5.839 Mean :3.028 Mean :3.752 Mean : 1.331 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.: 1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :23.000 ## NA&#39;s :2 NA&#39;s :3 NA&#39;s :3 NA&#39;s :2 ## Species Location ## setosa :49 Canada:35 ## versicolor:50 China : 6 ## virginica :49 Japan :11 ## NA&#39;s : 2 Korea :10 ## Russia:11 ## USA :63 ## NA&#39;s :14 Looking for anamolous data hist(irisz$Sepal.Length) hist(irisz$Sepal.Width) hist(irisz$Petal.Length) hist(irisz$Petal.Width) how to filter entries in a data.frame how to cast/transform value Types how to scale/normalize values head(irisz$Sepal.Length) ## [1] 5.1 4.9 4.7 4.6 5.0 5.4 ?scale x &lt;- 1:10 scale(x) ## [,1] ## [1,] -1.4863011 ## [2,] -1.1560120 ## [3,] -0.8257228 ## [4,] -0.4954337 ## [5,] -0.1651446 ## [6,] 0.1651446 ## [7,] 0.4954337 ## [8,] 0.8257228 ## [9,] 1.1560120 ## [10,] 1.4863011 ## attr(,&quot;scaled:center&quot;) ## [1] 5.5 ## attr(,&quot;scaled:scale&quot;) ## [1] 3.02765 scale(x, center = FALSE) ## [,1] ## [1,] 0.1528942 ## [2,] 0.3057883 ## [3,] 0.4586825 ## [4,] 0.6115766 ## [5,] 0.7644708 ## [6,] 0.9173649 ## [7,] 1.0702591 ## [8,] 1.2231533 ## [9,] 1.3760474 ## [10,] 1.5289416 ## attr(,&quot;scaled:scale&quot;) ## [1] 6.540472 scale(x, scale = FALSE) ## [,1] ## [1,] -4.5 ## [2,] -3.5 ## [3,] -2.5 ## [4,] -1.5 ## [5,] -0.5 ## [6,] 0.5 ## [7,] 1.5 ## [8,] 2.5 ## [9,] 3.5 ## [10,] 4.5 ## attr(,&quot;scaled:center&quot;) ## [1] 5.5 head(scale(irisz$Sepal.Length)) ## [,1] ## [1,] -0.8992245 ## [2,] -1.1425248 ## [3,] -1.3858250 ## [4,] -1.5074751 ## [5,] -1.0208747 ## [6,] -0.5342742 library(scales) rescale(x) ## [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667 ## [8] 0.7777778 0.8888889 1.0000000 3.2 Using tidyverse When it comes to manipulating data frames (creating new columns, filtering, etc.) - tidyverse is your friend! Scholars will understand the complex socio-technical context of tidyverse, ie that it’s not base R but oh boy it’s popular and well supported by a company - but not base R Scholars know that tidyverse/dplyr takes a more database-like approach to moving data tables around Scholars can identify and predict what a magrittr pipe does Scholars can pipe some stuff between functions, and write that out in a script Scholars can filter data tables, select and rename columns Scholars can mutate columns Scholars understand what group_by is doing Scholars can use group_by to summarise variables # ? 3.3 Using tidyverse When it comes to manipulating data frames (creating new columns, filtering, etc.) - tidyverse is your friend! Scholars will understand the complex socio-technical context of tidyverse, ie that it’s not base R but oh boy it’s popular and well supported by a company - but not base R Scholars know that tidyverse/dplyr takes a more database-like approach to moving data tables around Scholars can identify and predict what a magrittr pipe does Scholars can pipe some stuff between functions, and write that out in a script Scholars can filter data tables, select and rename columns Scholars can mutate columns Scholars understand what group_by is doing Scholars can use group_by to summarise variables # ? 3.4 Making plots with ggplot2 We will primarily be working in ggplot2 as it has the greatest degree of customization for visualization and offers many additional features over the basic plotting in R. library(ggplot2) library(tidyverse) 3.4.1 Getting started with a ggplot Most ggplot calls to create a figure take the following form (you can read more using help(ggplot)): ggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;() We will practice using our mammalian sleep dataset. You can look up more info about this dataset using the help function and the dataset name, msleep. head(msleep) ## # A tibble: 6 x 11 ## name genus vore order conservation sleep_total sleep_rem sleep_cycle awake ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Cheetah Acin… carni Carn… lc 12.1 NA NA 11.9 ## 2 Owl mo… Aotus omni Prim… &lt;NA&gt; 17 1.8 NA 7 ## 3 Mounta… Aplo… herbi Rode… nt 14.4 2.4 NA 9.6 ## 4 Greate… Blar… omni Sori… lc 14.9 2.3 0.133 9.1 ## 5 Cow Bos herbi Arti… domesticated 4 0.7 0.667 20 ## 6 Three-… Brad… herbi Pilo… &lt;NA&gt; 14.4 2.2 0.767 9.6 ## # … with 2 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt; You will first use the ggplot() function and bind the plot to a specific data frame using the data argument. ggplot(data = msleep) You will next need to define a mapping (using the aesthetic or aes function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x/y positions or characteristics such as size, shape, color, etc. ggplot(data = msleep, aes(x = brainwt, y = sleep_rem)) You can then add ‘geoms’ – graphical representations of the data in the plot (points, lines, bars). ggplot2 offers many different geoms. We will use some common ones today including: geom_point() for scatter plots, dot plots, etc. geom_boxplot() for, well, boxplots! geom_line() for trend lines, time series, etc. To add a geom to the plot use the + operator. Because we have two continuous variables, let’s use geom_point() first: ggplot(data = msleep, aes(x = brainwt, y = sleep_rem)) + geom_point() To save your work-in-progress, you can assign the plot to a variable. my_plot &lt;- ggplot(data = msleep, aes(x = brainwt, y = sleep_rem)) We can now draw the plot as a scatterplot with points to represent each state. my_plot + geom_point() ## Warning: Removed 35 rows containing missing values (geom_point). You might notice that all of the points are squished against the y-axis since many of the mammals in this dataset have low brain weights. summary(msleep$brainwt) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.00014 0.00290 0.01240 0.28158 0.12550 5.71200 27 As you can see with the summary function, the minimum and median values are very low, but there are a few mammals with high brainwt as you can see by the much larger maximum value in this vector. To make more useful plots, we can transform this value using log-scaling. While we will have to note that the new values do not exactly match the real-world measurements anymore, patterns we see (i.e. something that correlates with higher brain weights) will still hold true. msleep2 &lt;- msleep %&gt;% mutate(brainwt_log = log(brainwt)) ggplot(msleep2, aes(x = brainwt_log, y = sleep_rem)) + geom_point() ## Warning: Removed 35 rows containing missing values (geom_point). Here we use the mutate function to make a new variable called brainwt_log in our dataset (technically a new dataset copy that we have saved as msleep2). Plotting this variable as our x variable (i.e. independent variable), makes it easier to look for patterns. 3.4.2 Changing plot aesthetics We can modify the appearance of the plot in two ways: either uniformly changing the appearance or having the appearance vary depending on information present in our data. Let’s explore how to modify our plots uniformly. We can change aspects of the points we plot such as transparency (“alpha”) and color by supplying them as arguments in the geom_point function. ggplot(data = msleep2, aes(x = brainwt_log, y = sleep_rem)) + geom_point(alpha = 0.5, color = &quot;blue&quot;) ## Warning: Removed 35 rows containing missing values (geom_point). Here we have made the plots semi-transparent and colored blue. You can try varying these values (e.g. change blue to a different color). You can also supply other arguments such as shape to use something other than a dot. However, it is also possible to scale the color of the points by some variable present in the data. This approach means we can create a scatterplot that conveys more than just two variables’ worth of information (x-axis and y-axis) by having the color reflect a third variable. To do this, we specify the color inside the aesthetic mapping aes within the initial ggplot function. Same as how we told R to use a specific column by name for x or y coordinates, we specify which column to use for color. ggplot(msleep2, aes(x = brainwt_log, y = sleep_rem, color = vore)) + geom_point() ## Warning: Removed 35 rows containing missing values (geom_point). This plot conveys not only the relationship between brainwt_log and sleep_rem, but each plot representing a different mammal now conveys what the feeding behavior of that mammal is. When generating visualizations, it is important to annotate the figure with meaningful labels on the axes to make them accessible for the viewer. For that, we can use the labs function. ggplot(msleep2, aes(x = brainwt_log, y = sleep_rem, color = vore)) + geom_point() + labs(x = &quot;Brain Weight (log)&quot;, y = &quot;Duration of REM Sleep&quot;) ## Warning: Removed 35 rows containing missing values (geom_point). 3.4.3 Exploring simple plots Let’s consider how we make other plots besides a scatterplot. Scatterplots are a great way to look at two quantitative (numerical) values at the same time to observe patterns (i.e. correlations) between the variables or to identify interesting outliers. However, other plots may be more useful to look at differing numbers of variables (i.e. one quantitative variable) or different types of variables (i.e. qualitative or categorical data). Here, we discuss two types of single variable plots that look at either a quantitative variable (histogram) or a categorical variable (barplot). We can create histograms in ggplot2 that are more aesthetically pleasing than the default hist function. This shows the distribution of one quantitative variable. ggplot(msleep, aes(x = sleep_total)) + geom_histogram(bins = 10) We can look at how many individuals in the dataset fall into each category, such as how many mammals have each kind of feeding behavior. ggplot(data = msleep, aes(x = vore)) + geom_bar() As you can see where we map the aesthetic, we only tell the ggplot function to refer to a single column in our dataset for our x-axis. 3.4.4 Visualizing between groups Let’s return to iris dataset to explore how we can visualize differences between groups/categories. These groups are often represented in our data as a factor. We can look at how the distributions of Sepal.Length differ depending on which species each iris belongs to. One plot that can do this easily is the geom_boxplot function. ggplot(data = iris, aes(x = Species, y = Sepal.Length)) + geom_boxplot() By adding a different parameter to fill in the aes we define throgh the ggplot function, we can separate out histograms according to different groupings. Here, we use Species to determine the color of the fill. ggplot(iris, aes(x = Sepal.Length, fill = Species)) + geom_histogram(bins = 10) While we can sort of see the trends on this plot, it may be helpful to separate out each histogram for each individual species. There is an easy way to do this in ggplot2 using facetting or the facet_wrap function. This function splits the figure into separate panel where the data has been filtered by the category (i.e. Species). ggplot(iris, aes(x = Sepal.Length, fill = Species)) + geom_histogram(bins = 10) + facet_wrap( ~ Species) This matches what we already saw in the boxplot, showing that there are different sepal lengths depending on which iris species we look at. We will explore in the next section how we know if these differences are significant. 3.4.5 Generating heatmaps Heatmaps are a useful way to show the values of multiple samples across many measurements. You can visualize a heatmap by thinking of your dataframe, this tabular data, if it had each cell colorcoded based on how high or low the value is. The base R heatmap function meets many needs while the ggplot2 equivalent (geom_tile) can be confusing so we will recommend that you not use ggplot2 for heatmaps. Let’s go back to msleep dataset to visualize trends between the different measurements taken on each mammal. We will first create a simplified dataset from msleep where we take the log value of both brainwt and bodywt. temp.data &lt;- cbind(log(msleep$brainwt), log(msleep$bodywt)) head(temp.data) ## [,1] [,2] ## [1,] NA 3.9120230 ## [2,] -4.1669153 -0.7339692 ## [3,] NA 0.3001046 ## [4,] -8.1456296 -3.9633163 ## [5,] -0.8603831 6.3969297 ## [6,] NA 1.3480731 Next, we feed these numeric values into the heatmap function along with some arguments that specify settings for displaying the figure. We use labCol to specify how to label these columns and cexCol to control the text size of these labels. We set labRow to be the names of each species from the msleep dataset. heatmap(temp.data, labRow = msleep$name, labCol = c(&quot;brainwt&quot;, &quot;bodywt&quot;), cexCol = 1) This first heatmap will look strange because it colors each box by its magnitude, but body weight of a mammal is always greater than its brain weight. We want to scale within each column so that the depth of the color reflects whether the mammal has a high brain weight or high body weight relative to the other mammals. heatmap(temp.data, scale = &quot;col&quot;, labRow = msleep$name, labCol = c(&quot;brainwt&quot;, &quot;bodywt&quot;), cexCol = 1) Using the scale argument which we set to &quot;col&quot;, now the color of the columns is more meaningful. For example, it makes sense that the measurements taken on an Asian elephant are much higher than those from a mole rat, so the color of those cells is deeper. Let’s add some more data to our heatmap visualization. temp.data2 &lt;- cbind(temp.data, msleep$sleep_total, msleep$sleep_rem) heatmap(temp.data2, scale = &quot;col&quot;, labRow = msleep$name, labCol = c(&quot;brainwt&quot;, &quot;bodywt&quot;, &quot;total_sleep&quot;, &quot;rem_sleep&quot;), cexCol = 1) You may have noticed the weird diagrams along the top and left hand side of this heatmap. These strange line diagrams are trees that show how our samples cluster together. Mammals that have similar patterns of values across these four measurements are placed near each other in the diagram. 3.5 Making scientific figures Making plots can be a great way to develop an intuition for your dataset, though to derive and communicate scientific insights, we need to have an idea of the uncertainty in our interpretations. Uncertainty describes ideas such as: are the values between two groups different enough, that it is unlikely that the differences are due to chance? Is the correlation between these variables strong enough that one can predict the other, with some level of confidence? How statistically significant are the patterns we see? 3.5.1 Plotting error bars When we compare measurements taken from two samples (i.e. two groups), we might want to see if the two groups have very different values for that specific measurement. If we have multiple observations within each group, we can take a summary statistic such as the mean or median and plot those against each other. ggplot(msleep2, aes(x = vore, y = awake)) + geom_bar(stat = &quot;summary&quot;, fun = &quot;mean&quot;) For example, here we have asked our geom_bar function to plot a summary, specifically the mean of each group, instead of plotting identity which usually means the value as is. Looking at this figure, we can’t guess if the groups are significantly different without an idea of the uncertainty in our measurements through something like error bars. Here is the convention for plotting error bars in ggplot2, as you can see it is just another kind of geom that we can add to our plot: ggplot(data = &lt;SUMMARY DATA&gt;, mapping = aes(&lt;SUMMARY MAPPINGS&gt;) + geom_bar(stat = &quot;identity&quot;) + geom_errorbar(aes(&lt;ERROR MAPPINGS&gt;)) This method is straightforward, but you need to have pre-calculated the summary statistic for each group and the amount of error (i.e. standard error) from your data. That “aggregated” dataframe becomes the data that you provide to ggplot, instead of the original dataset. feeding.data &lt;- msleep2 %&gt;% group_by(vore) %&gt;% summarize(mean_se(awake)) feeding.data ## # A tibble: 5 x 4 ## vore y ymin ymax ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 carni 13.6 12.6 14.7 ## 2 herbi 14.5 13.6 15.4 ## 3 insecti 9.06 6.41 11.7 ## 4 omni 13.1 12.4 13.7 ## 5 &lt;NA&gt; 13.8 12.7 14.9 What does mean_se do? ?mean_se y is the mean ymin is mean - one SE ymax is mean + one SE ggplot(feeding.data, aes(x = vore, y = y)) + geom_bar(stat = &quot;identity&quot;) Here we create the same plot as before from this aggregated dataset, just showing the mean value in each group. ggplot(feeding.data, aes(x = vore, y = y)) + geom_bar(stat = &quot;identity&quot;) + geom_errorbar(aes(ymin = ymin, ymax = ymax), width = 0.2) Now we add the error bars, mapping the ymin and ymax values to show where the bottom and top of each error bar should be. 3.5.2 Showing trends in data Lots of these different figures summarize or aggregate the data. We may want to display the data with the individual points, but still show the overall trend across the data. msleep3 &lt;- msleep2 %&gt;% mutate(bodywt_log = log(bodywt)) ggplot(data = msleep3, mapping = aes(x = brainwt_log, y = bodywt_log)) + geom_density_2d() + geom_point() ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_density_2d() + geom_point() We can add a trendline with geom_smooth that you can check using help(geom_smooth). my.plot &lt;- ggplot(msleep3, aes(x = brainwt_log, y = bodywt_log)) + geom_point(alpha = 0.5) + geom_smooth() my.plot ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; We can also do this with trendlines that summarize only certain subsets of the data, such as ? ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point() + geom_smooth(aes(color = Species)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; The above plot reflects the trends, but makes it hard to see the data that is contributing to each trend line. These differences can be most easily seen using facet_wrap or facetting that splits the figure into separate panel where the data has been filtered by the category (i.e. ?). ggplot(data = iris, mapping = aes(x = Sepal.Length, y = Sepal.Width)) + geom_point() + geom_smooth(aes(color = Species)) + facet_wrap( ~ Species) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 3.5.3 Saving figures locally As you produce analysis in your research, you may want to create high-quality images of your figures to then use in presentations or publications. There are two easy ways to save images as an individual file on your computer, The first method uses ggsave to save the most recent ggplot figure you generated. ggplot(msleep2, aes(x = brainwt_log, y = sleep_rem)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ggsave(&quot;plot.png&quot;, width = 5, height = 5) This function will save wherever your directory is currently. Check with getwd() and change with setwd(folder name). You can also provide a precise file path in the new file name. ggsave(&quot;~/Downloads/plot.png&quot;, width = 5, height = 5) Here is an alternative method for saving your figures: pdf(&quot;plot.pdf&quot;) # creates the file # png() also works if you want a different file format ggplot(msleep2, aes(x = brainwt_log, y = sleep_rem)) + geom_point() + geom_smooth(method = &quot;lm&quot;) dev.off() # finishes editing the file Any changes to the figure that are contained between the initial creation of the figure (i.e. the pdf command) and the dev.off command will be included in the final saved image. However, the figure is being printed directly to the file it is writing and won’t appear elsewhere. 3.6 Applying basic stats Objective 4.x: Scholars will have a sense for how to implement more advanced statistical tests in R Scholars will be able to identify and use correlation functions, use different kinds of correlation, know how to deal with NAs Scholars will be able to identify and use linear regression lm() using both raw variable and formulaic interfaces Scholars will be able to plot error bars Scholars will be able to calculate and plot confidence intervals head(msleep) ## # A tibble: 6 x 11 ## name genus vore order conservation sleep_total sleep_rem sleep_cycle awake ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Cheetah Acin… carni Carn… lc 12.1 NA NA 11.9 ## 2 Owl mo… Aotus omni Prim… &lt;NA&gt; 17 1.8 NA 7 ## 3 Mounta… Aplo… herbi Rode… nt 14.4 2.4 NA 9.6 ## 4 Greate… Blar… omni Sori… lc 14.9 2.3 0.133 9.1 ## 5 Cow Bos herbi Arti… domesticated 4 0.7 0.667 20 ## 6 Three-… Brad… herbi Pilo… &lt;NA&gt; 14.4 2.2 0.767 9.6 ## # … with 2 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt; median(msleep$brainwt, na.rm = TRUE) ## [1] 0.0124 mean(msleep$brainwt, na.rm = TRUE) ## [1] 0.2815814 sd(msleep$brainwt, na.rm = TRUE) ## [1] 0.9764137 var(msleep$brainwt, na.rm = TRUE) ## [1] 0.9533837 median(msleep$bodywt, na.rm = TRUE) ## [1] 1.67 mean(msleep$bodywt, na.rm = TRUE) ## [1] 166.1363 sd(msleep$bodywt, na.rm = TRUE) ## [1] 786.8397 var(msleep$bodywt, na.rm = TRUE) ## [1] 619116.8 hist(msleep$brainwt) cor(msleep$brainwt, msleep$bodywt) ## [1] NA summary(msleep) ## name genus vore order ## Length:83 Length:83 Length:83 Length:83 ## Class :character Class :character Class :character Class :character ## Mode :character Mode :character Mode :character Mode :character ## ## ## ## ## conservation sleep_total sleep_rem sleep_cycle ## Length:83 Min. : 1.90 Min. :0.100 Min. :0.1167 ## Class :character 1st Qu.: 7.85 1st Qu.:0.900 1st Qu.:0.1833 ## Mode :character Median :10.10 Median :1.500 Median :0.3333 ## Mean :10.43 Mean :1.875 Mean :0.4396 ## 3rd Qu.:13.75 3rd Qu.:2.400 3rd Qu.:0.5792 ## Max. :19.90 Max. :6.600 Max. :1.5000 ## NA&#39;s :22 NA&#39;s :51 ## awake brainwt bodywt ## Min. : 4.10 Min. :0.00014 Min. : 0.005 ## 1st Qu.:10.25 1st Qu.:0.00290 1st Qu.: 0.174 ## Median :13.90 Median :0.01240 Median : 1.670 ## Mean :13.57 Mean :0.28158 Mean : 166.136 ## 3rd Qu.:16.15 3rd Qu.:0.12550 3rd Qu.: 41.750 ## Max. :22.10 Max. :5.71200 Max. :6654.000 ## NA&#39;s :27 msleep2 &lt;- msleep %&gt;% drop_na(brainwt) dim(msleep) ## [1] 83 11 dim(msleep2) ## [1] 56 11 cor(msleep2$brainwt, msleep2$bodywt) ## [1] 0.9337822 library(Hmisc) ## Loading required package: lattice ## Loading required package: survival ## Loading required package: Formula ## ## Attaching package: &#39;Hmisc&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## src, summarize ## The following objects are masked from &#39;package:base&#39;: ## ## format.pval, units rcorr(msleep2$brainwt, msleep2$bodywt, type = &quot;pearson&quot;) ## x y ## x 1.00 0.93 ## y 0.93 1.00 ## ## n= 56 ## ## ## P ## x y ## x 0 ## y 0 rcorr(msleep2$brainwt, msleep2$bodywt, type = &quot;spearman&quot;) ## x y ## x 1.00 0.96 ## y 0.96 1.00 ## ## n= 56 ## ## ## P ## x y ## x 0 ## y 0 my.mod &lt;- lm(formula = brainwt ~ bodywt, data = msleep2) summary(my.mod) ## ## Call: ## lm(formula = brainwt ~ bodywt, data = msleep2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.78804 -0.08422 -0.07634 -0.02839 2.06190 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.592e-02 4.821e-02 1.782 0.0804 . ## bodywt 9.639e-04 5.027e-05 19.176 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3526 on 54 degrees of freedom ## Multiple R-squared: 0.8719, Adjusted R-squared: 0.8696 ## F-statistic: 367.7 on 1 and 54 DF, p-value: &lt; 2.2e-16 my.mod2 &lt;- lm(formula = sleep_total ~ bodywt + brainwt, data = msleep2) summary(my.mod2) ## ## Call: ## lm(formula = sleep_total ~ bodywt + brainwt, data = msleep2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.4531 -2.2517 -0.2619 2.0531 9.2283 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.6722485 0.5898643 18.093 &lt;2e-16 *** ## bodywt 0.0007953 0.0016703 0.476 0.636 ## brainwt -2.3518943 1.6180072 -1.454 0.152 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.193 on 53 degrees of freedom ## Multiple R-squared: 0.1337, Adjusted R-squared: 0.101 ## F-statistic: 4.088 on 2 and 53 DF, p-value: 0.02232 my.mod2 &lt;- lm(formula = sleep_total ~ bodywt + brainwt, data = msleep2) summary(my.mod2) ## ## Call: ## lm(formula = sleep_total ~ bodywt + brainwt, data = msleep2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.4531 -2.2517 -0.2619 2.0531 9.2283 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.6722485 0.5898643 18.093 &lt;2e-16 *** ## bodywt 0.0007953 0.0016703 0.476 0.636 ## brainwt -2.3518943 1.6180072 -1.454 0.152 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.193 on 53 degrees of freedom ## Multiple R-squared: 0.1337, Adjusted R-squared: 0.101 ## F-statistic: 4.088 on 2 and 53 DF, p-value: 0.02232 "],["day-5-building-workflows.html", "4 Day 5 - building workflows 4.1 Using code many times - loops 4.2 Writing (re)usable code 4.3 Functions redux - why they’re so great 4.4 Using functions to write modular code 4.5 Packages are chunks of code (and sometimes data) 4.6 Finding more help and documentation 4.7 Reproducibile sharing - more rmarkdown and 4.8 Reproducibility and sharing 4.9 Troubleshooting, getting help, dissecting problems 4.10 Conclusion, other concepts", " 4 Day 5 - building workflows Today we’re going to learn about applying these R skills to repeat, reproduce, extend, and share your analyses. First, let’s review the last two days. What have we done? How do we do it many times? Crack open your code - can you use it again? Can you adapt it to modify your question, feed in new data, and modify the scientifically-important bits easily? Can you share it with someone and they follow along? 4.1 Using code many times - loops You will want to do the same thing multiple times - automation is great. Let’s code up a simple little analysis - we’ll calculate the length (number of amino acids) in a viral structural protein sequence. These files are in the data/viral_structural_proteins folder, are tab-delimited three fields, and look like this: Q8V433.1 Membrane protein Bovine respiratory coronavirus (strain 98TXSF-110-LUN) MSSVTTPAPVYTWTA... Let’s read one in. We’ll need to use read.delim, specify a tab separator, and ignore the lack of a header. viral_protein_data &lt;- read.delim(&quot;data/viral_structural_proteins/viral_proteins_100.tsv&quot;, sep=&quot;\\t&quot;,header=F) viral_protein_data ## V1 ## 1 Q8V433.1 Membrane protein ## V2 ## 1 Bovine respiratory coronavirus (strain 98TXSF-110-LUN) ## V3 ## 1 MSSVTTPAPVYTWTADEAIKFLKEWNFSLGIILLFITVILQFGYTSRSMFVYVIKMIILWLMWPLTIILTIFNCVYALNNVYLGFSIVFTIVAIIMWIVYFVNSIRLFIRTGSWWSFNPETNNLMCIDMKGRMYVRPIIEDYHTLTVTIIRGHLYMQGIKLGTGYSLSDLPAYVTVAKVSHLLTYKRGFLDKIGDTSGFAVYVKSKVGNYRLPSTQKGSGLDTALLRNNI How do we find the column names? What are two ways to access the protein sequence? How do we calculate the number of characters in this sequence? Code it up! 4.1.1 Doing things multiple times Let’s do this for all the proteins. The simplest way of doing this is to copy and paste it. viral_protein_data &lt;- read.delim(&quot;data/viral_structural_proteins/viral_proteins_002.tsv&quot;, sep=&quot;\\t&quot;,header=F, as.is=T) nchar(viral_protein_data$V3[[1]]) ## [1] 177 viral_protein_data &lt;- read.delim(&quot;data/viral_structural_proteins/viral_proteins_003.tsv&quot;, sep=&quot;\\t&quot;,header=F, as.is=T) nchar(viral_protein_data[1,&quot;V3&quot;]) ## [1] 137 Go ahead and do this for all 242 proteins … just kidding. Try this to, well, list files: list.files(path=&quot;data/viral_structural_proteins&quot;)[1:5] ## [1] &quot;viral_proteins_000.tsv&quot; &quot;viral_proteins_001.tsv&quot; &quot;viral_proteins_002.tsv&quot; ## [4] &quot;viral_proteins_003.tsv&quot; &quot;viral_proteins_004.tsv&quot; Note that I put a [1:5] to limit it to the first 5. You could also use head(). It’s a good idea to work with a small subset of files while you are iterating through development, then scale it up to the entirety. Now how do you calculate the number of characters for each protein? How do we do this for every file listed … ? 4.1.2 Loops Loops are for running a “code block” as many times as the “condition” determines. A “code block” is either one line of code, or multiple lines of code surrounded by curly brackets - {} { code &lt;- &quot;in a block&quot; with &lt;- &quot;multiple lines&quot; } A “condition” is an expression of code that can either evaluate to either TRUE or FALSE, or set a variable for each time running the code block. The most common form of this is a for loop. Other “control statements” or “flow control statements” are while, repeat, and if. Let’s look up what they do, with “?for” Note the back ticks! These are a trick in R to make anything be interpreted as literally what you type, and not any special characters. Like “?+”, or “??” Here’s an example loop: for (i in 1:4) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 The pieces: (i in 1:4) is what is being looped over - 1:4 is a vector of 1 through 4 that is created, and it is put one at a time into i (a new variable). You need the parentheses. { and } denote the opening and closing brackets, specify the “code block” that is run each time. inside this “code block” is print(i) - it prints the variable i, which is set to a value of 1, 2, 3, or 4 for each loop How do we loop through and print each file name? What are the (1) code block and (2) loop condition ? for (i in list.files(path=&quot;data/viral_structural_proteins&quot;)[1:5] ) { print(i) } ## [1] &quot;viral_proteins_000.tsv&quot; ## [1] &quot;viral_proteins_001.tsv&quot; ## [1] &quot;viral_proteins_002.tsv&quot; ## [1] &quot;viral_proteins_003.tsv&quot; ## [1] &quot;viral_proteins_004.tsv&quot; How do we modify this to calculate the protein length? for (i in list.files(path=&quot;data/viral_structural_proteins&quot;)[1:5] ) { print(i) print(nchar(read.delim(i)$V3[[1]])) } ## [1] &quot;viral_proteins_000.tsv&quot; ## Warning in file(file, &quot;rt&quot;): cannot open file &#39;viral_proteins_000.tsv&#39;: No such ## file or directory ## Error in file(file, &quot;rt&quot;): cannot open the connection Debugging… for (i in list.files(path=&quot;data/viral_structural_proteins&quot;, full.names=T)[1:5] ) { print(nchar(read.delim(i,sep=&quot;\\t&quot;,header=F,as.is=T)$V3[[1]])) } ## [1] 1248 ## [1] 1254 ## [1] 177 ## [1] 137 ## [1] 117 4.1.2.1 Storing values from a loop How do we store this value? In other languages, “append”. But R is not built that way. It’ll work, but it’s very inefficient. The “R-way” to store values from a loop is to define a vector of the right length, then put each element in it. vector(&quot;character&quot;,10) ## [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; vector(mode=&quot;numeric&quot;,length=5) ## [1] 0 0 0 0 0 vector(&quot;logical&quot;,2) ## [1] FALSE FALSE Okay, but how do we access each position to save the value? We need to turn out list of files into indicies. We’ll save it first so we can count how many there are. seq_along is handy function, otherwise use something like seq(1,length(x)). first_five &lt;- list.files(path=&quot;data/viral_structural_proteins&quot;)[1:5] for (i in seq_along(first_five) ) { print(first_five[i]) } ## [1] &quot;viral_proteins_000.tsv&quot; ## [1] &quot;viral_proteins_001.tsv&quot; ## [1] &quot;viral_proteins_002.tsv&quot; ## [1] &quot;viral_proteins_003.tsv&quot; ## [1] &quot;viral_proteins_004.tsv&quot; Putting these together, we can save a vector of file names: first_five &lt;- list.files(path=&quot;data/viral_structural_proteins&quot;)[1:5] filenamez &lt;- vector(&quot;character&quot;,length(first_five)) for (i in seq_along(first_five) ) { filenamez[i] &lt;- first_five[i] } filenamez ## [1] &quot;viral_proteins_000.tsv&quot; &quot;viral_proteins_001.tsv&quot; &quot;viral_proteins_002.tsv&quot; ## [4] &quot;viral_proteins_003.tsv&quot; &quot;viral_proteins_004.tsv&quot; And finally calculate the length of each protein: first_five &lt;- list.files(path=&quot;data/viral_structural_proteins&quot;, full.names=T, pattern=&quot;.*tsv&quot;)[1:5] lengthz &lt;- vector(&quot;character&quot;,length(first_five)) for (i in seq_along(first_five) ) { lengthz[i] &lt;- nchar( read.delim(first_five[i], header=F,as.is=T,sep=&quot;\\t&quot;)$V3[[1]] ) } lengthz ## [1] &quot;1248&quot; &quot;1254&quot; &quot;177&quot; &quot;137&quot; &quot;117&quot; Now we can take off the [1:5] limiter, and do the whole set: first_five &lt;- list.files(path=&quot;data/viral_structural_proteins&quot;, full.names=T, pattern=&quot;.*tsv&quot;) lengthz &lt;- vector(&quot;character&quot;,length(first_five)) for (i in seq_along(first_five) ) { lengthz[i] &lt;- nchar( read.delim(first_five[i], header=F,as.is=T,sep=&quot;\\t&quot;)$V3[[1]] ) } How do we go about visualizing/analyzing this? hist(lengthz) ## Error in hist.default(lengthz): &#39;x&#39; must be numeric er what…? Numeric…. first_five &lt;- list.files(path=&quot;data/viral_structural_proteins&quot;, full.names=T, pattern=&quot;.*tsv&quot;) lengthz &lt;- vector(&quot;numeric&quot;,length(first_five)) for (i in seq_along(first_five) ) { lengthz[i] &lt;- nchar( read.delim(first_five[i], header=F,as.is=T,sep=&quot;\\t&quot;)$V3[[1]] ) } hist(lengthz,breaks=50) library(ggplot2) ggplot( data.frame(length=lengthz) )+theme_classic()+ aes(x=length)+geom_histogram(bins=50) summary(lengthz) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.0 231.5 646.0 729.2 1089.0 3390.0 4.2 Writing (re)usable code Crack open your code - can you use it again? Can you adapt it to modify your question, feed in new data, and modify the scientifically-important bits easily? 4.2.0.1 Examples Let’s look at two chunks of code from a paper (lightly edited). The experiment is counting barcoded lineages of yeast cells to estimate “PPIs” (protein-protein interactions) 1 Here’s an example of one style of writing R script: # filter out bad barcode lineages ( &lt;= 2 time points counts &gt; 0, or maximum of each time point &lt;= 5 or total counts of a lineage &lt; 10) bad_index = rep(0, nrow(DBC_known_counts)) for(i in 1:length(bad_index)){ counts = as.numeric(DBC_known_counts[i, 4:8]) if (length(which(counts != 0)) &lt; 3 | max(counts) &lt; 5 | sum(counts) &lt; 10){ bad_index[i] = 1 } } length(which(bad_index == 1)) # 1447775 What is going on here? How do you feed in new data? How do you run this multiple times? How do you change the logic? Here’s another example from the same author: H202_Output &lt;- PPI_calling_sigmoid( PPI_multiple=dataFrameReader_T(&quot;/Volumes/zmliu_02/PPiseq_03/H2O2/counts/PPI_multiple_p.values.csv&quot;), specific_PPV=c(seq(0.5,0.58,by=0.02),seq(0.6,0.8,by=0.01),seq(0.82,0.9,by=0.02)), Fitness=fitness(0,1,0.01), p_value=seq(-4,0,0.1), Neg_number_PPI=6e4, Neg_ref_number=50, p_threshold=-4 p_loc=6, ) Same questions. What are some differences? What’s useful for you? What’s a lot of effort to do? 4.2.1 Style guides can be inspiring tidyverse style guide google-specific changes Jean Fan’s search for “R style guide” What style should you use? Be inconsistently consistent! Balance for yourself: How easy is it to write? How easy is it for you to read? How easy is it for others to read? How similar is it to what everyone else is doing (a very good thing)? But most importantly, use what folks around you are using. Be lazy, imitate others! How would you describe your code writing style? How do you name things? How good are your comments? What ideas would you like to incorporate? 4.3 Functions redux - why they’re so great Functions are handy. For example, let’s calculate the standard error of a sample of values: values &lt;- c(4,3,2,2,5,3,6,2,2,4) stderr(values) ## Error in stderr(values): unused argument (values) Er … what? What does stderr do? ?stderr How do you calculate the standard error of the mean of a sample? sd(values)/sqrt(length(values)) ## [1] 0.4484541 Do we want to type this each time, copy and paste the code each time? values2 &lt;- c(10,30,20) sd(values2)/sqrt(length(values)) ## [1] 3.162278 This can lead to errors in writing, small incorrect parts. It also leaves all the complexity to the reader, so it makes it harder to understand when reading code - hard to notice small details. Where do we save it, how do we share it? Copy and pasting from a file is okay, but it takes up a lot more work/space. We could email around a file of code chunks, or share on github. How do we make sure it works? This is hard to do with copy-paste code chunks. Changing the chunk to work on a new input can be an opportunity for introducing errors, typos. 4.3.0.1 Write it as a function! What are the parameters? Are any defaults set? What does it return? These can be copy and pasted, or source()’d from a .R file. Once you run it, you can test it and change inputs easily. Later, you could change the function and keep the same script of using the function. sez &lt;- function(x) {sd(x)/sqrt(length(x))} sez(values) ## [1] 0.4484541 sez(rnorm(10)) ## [1] 0.223197 sez(rnorm(100)) ## [1] 0.1157716 sez(rpois(1e3,3)) ## [1] 0.05433485 4.4 Using functions to write modular code How might you carry out the workflow from the previous work to calculate protein sequence lengths? One way is to flatten out all the tasks, and to script each individual task each time. This requires the author, user, and reader to understand a lot of complexity. graph TD classDef default line-height:10px; classDef three line-height:10px,fill:yellow; you[analyst] --> B[finding files] & C[making a vector] & D[looping] & E[reading files] & F[getting protein seq] & G[calculting and saving nchar] & H[plotting nchar] B:::three; C:::three; D:::three; E:::three; F:::three; G:::three; H:::three; Another way to approach this is to cluster them into a hierarchy of modules. graph TD classDef default line-height:10px; classDef one line-height:10px,fill:pink; classDef two line-height:10px,fill:cyan; classDef three line-height:10px,fill:yellow; you2[analyst] --> find & read & plot; find:::one --> B; B[finding files]:::three; read:::one --> looping & reading; looping:::two --> C & D; C[making a vector]:::three; D[looping]:::three; reading[reading and calc]:::two --> E & F & G; E[reading files]:::three; F[getting protein seq]:::three; G[calculting and saving nchar]:::three; plot:::one --> H; H[plotting nchar]:::three; In this organization, the analyst can operate at levels of steps, modules, and specific instructions, depending on what is needed. Organizing your workflows into composable modules lets you extend these to un-ancipiated complexity. You could imaging using these steps or modules: graph LR classDef default line-height:12px; vp[read viral proteins] --> cl[calculate lengths] --> hist[histogram] in new ways by composing the elements together, to analyze a different source of proteins, with a new analysis, with similar plots: graph LR classDef default line-height:12px; vp[read viral proteins] --> cl[calculate lengths] --> hist[histogram] hp[read human proteins] --> cl --> boxplot[boxplot] vp --> cgc[calculate GC%] --> gchist[histogram] hp --> cgc --> gcboxplot[boxplot] 4.4.1 Tips for modular workflows Try to not “hardcode” things - if it’s a number, consider if it can be a parameter that is “passed in” as an argument. Group repeated code functions - some folks say you should never repeat code (but do what works for you!). Try to read inputs and outputs as general, flexible formats - strings of filenames, vectors of values Write a comment at the top of the function that says what it’s doing and what to expect, generally comment things. Consider, the list.files() and hist() functions are already built this way! How about a ggplot2 style boxplot? 4.4.1.1 Let’s write a plotting module/function Write a function that makes a ggplot2 boxplot for some numbers. What should the function take, what should it do? What is “some numbers”? What should it return? wrap it in `print(ggplot code)` or return the ggplot object as a variable 4.4.2 More complex workflow Let’s write a simulation of viral evolution. (could be a bad idea, considering….) More examples/exercise show a simulation of something…. genetic drift of a virus replicating? lineage G1312F exercise - wrap the entire analysis as a function talk about ease of calling ease of tweaking this exercise - break into subfunctions, generate and plot ease of changing models 4.4.3 Apply is a popular tool Apply is another common way of doing something over and over. It is a very compact way to take pieces of a list, vector, dataframe, or matrix and put them into a function. There are: apply - for 2D objects lapply - for lists and vectors sapply - is lapply but with simplified returns mapply - is for combinations of multiple variables replicate - calls a function multiple times Some people strongly prefer coding this way. Here is an example: list_of_protein_files &lt;- lapply( list.files(&quot;data/viral_structural_proteins/&quot;,full.names=T), read.delim, sep=&quot;\\t&quot;,header=F) These “apply” some “FUN” to some input variables, by taking each element or slices of elements from input variables and putting them in as arguments to the function being applied. They return odd things, often lists (unlist()). 4.5 Packages are chunks of code (and sometimes data) Let’s take a look at your code from the last few days. How would you share this with the other people in the course? R, like other languages, is built on a package system - if you wrap up your code in particular expected ways and put it in particular expected places, it is very easy for others to get and use your code Packages are said to be easy to make, but they’re very easy to use. 4.5.1 CRAN is the canonical R package resource CRAN historical context library(&quot;stringdist&quot;) Call library() function, with an argument of the library name, as a string. get the stringdist library, use it get a new viz layer, use it 4.5.2 github is a common place for sharing code in development Installing from github requires some different programming - and there’s libraries with functions for this. library(&quot;devtools&quot;) or remotes? exercise - pull a package off github… ? maybe some sort of viz again? Exercise - install a package from github and learn how to use it Ghibli color palette Sports field plotting Ridgeplots in ggplot2 problems with this - security, eh 4.5.3 Bioconductor is a great place for bio-related packages 😬 How to install Bioconductor Scholars will know how to install Bioconductor package from CRAN Scholars will know how to find and install packages from Bioconductor explore the namespace for a package, ie ?packagename:: and TAB or ?packagename:: how to print out all the packages you have loaded 4.6 Finding more help and documentation Need a problem ?geom_line ?stringdist Objective X.X: Scholars will know how to get official docs ( ? ) and how to skim/read these Objective X.X: Scholars will see how easy it is to use a search engine to try and find other answers Objective X.X: Scholars will understand the intention of the Slack being a learning community, or something (set expectations about this) Source up problems from the class? Demo a weird plot idea, search for how to do it on stack overflow? Maybe how to change the color of facet labels in a ggplot facet graph, that’s a bit tricky and demonstrates why base R is important… 4.7 Reproducibile sharing - more rmarkdown and How are you saving your notes for this class? How do you usually save notes/code/instructions? How do you share this with others? 4.7.1 rmarkdown package 4.7.1.1 Background The rmarkdown package was created by Yihui Xie, extending from previous work and ideas in knitr and sweave. It’s a way of mixing writing with code, such that you can run the code and it makes a pretty doc (and more). video1 overview 4.7.1.2 Chunk options You can set chunk-level options in an Rmd, for each code chunk. Such as: ```{r, name_of_chunk, cache=T, fig.width=3, fig.height=2, error=F, warning=F, fig.align=&quot;right&quot;} x &lt;- 1:10 y &lt;- 1:10 plot(x,y) ``` x &lt;- 1:10 y &lt;- 1:10 plot(x,y) It is possible to enable figure captions. video2 chunk options 4.7.1.3 Document options You can set document-level options to. To do this, you create what’s called a YAML header, like so: --- title: &quot;Titled&quot; author: &quot;yours&quot; --- You need three hyphens to open and close it. Put it at the very beginning. You can define quite a few options, including themes, like so: --- title: &quot;Titled&quot; author: &quot;yours&quot; --- video3 head options 4.7.1.4 How it works, sort of… video4 how it does what it’s doing rmarkdown parses an Rmd file to extract out the R code. It runs this, using the chunk and other options to control this, then makes outputs from different chunks (text and plots). It then sticks the text and images into a markdown document, and uses a program called pandoc (included inside Rstudio) to turn that into HTML, PDF, and/or slides. 4.7.2 Sharing with others What does someone need to re-run your analyses? R (often Rstudio) what packages you’re using devtools::session_info() ## Error in get(genname, envir = envir) : object &#39;testthat_print&#39; not found ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.0.2 (2020-06-22) ## os macOS 10.16 ## system x86_64, darwin17.0 ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz America/Los_Angeles ## date 2021-06-04 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [2] CRAN (R 4.0.0) ## bookdown 0.22 2021-04-22 [1] CRAN (R 4.0.2) ## callr 3.7.0 2021-04-20 [1] CRAN (R 4.0.2) ## cli 2.5.0 2021-04-26 [1] CRAN (R 4.0.2) ## codetools 0.2-16 2018-12-24 [2] CRAN (R 4.0.2) ## crayon 1.4.1 2021-02-08 [1] CRAN (R 4.0.2) ## desc 1.2.0 2018-05-01 [2] CRAN (R 4.0.0) ## devtools 2.3.2 2020-09-18 [1] CRAN (R 4.0.2) ## digest 0.6.27 2020-10-24 [1] CRAN (R 4.0.2) ## ellipsis 0.3.2 2021-04-29 [1] CRAN (R 4.0.2) ## evaluate 0.14 2019-05-28 [2] CRAN (R 4.0.0) ## fs 1.5.0 2020-07-31 [1] CRAN (R 4.0.2) ## glue 1.4.2 2020-08-27 [1] CRAN (R 4.0.2) ## htmltools 0.5.1.9000 2021-01-26 [1] Github (rstudio/htmltools@e7f0393) ## knitr 1.30 2020-09-22 [1] CRAN (R 4.0.2) ## lifecycle 1.0.0 2021-02-15 [1] CRAN (R 4.0.2) ## magrittr 2.0.1 2020-11-17 [1] CRAN (R 4.0.2) ## memoise 1.1.0 2017-04-21 [1] CRAN (R 4.0.2) ## pkgbuild 1.1.0 2020-07-13 [1] CRAN (R 4.0.2) ## pkgload 1.1.0 2020-05-29 [2] CRAN (R 4.0.0) ## prettyunits 1.1.1 2020-01-24 [2] CRAN (R 4.0.0) ## processx 3.5.2 2021-04-30 [1] CRAN (R 4.0.2) ## ps 1.3.3 2020-05-08 [2] CRAN (R 4.0.0) ## purrr 0.3.4 2020-04-17 [2] CRAN (R 4.0.0) ## R6 2.5.0 2020-10-28 [1] CRAN (R 4.0.2) ## remotes 2.2.0 2020-07-21 [1] CRAN (R 4.0.2) ## rlang 0.4.10 2020-12-30 [1] CRAN (R 4.0.2) ## rmarkdown 2.6 2020-12-14 [1] CRAN (R 4.0.2) ## rprojroot 2.0.2 2020-11-15 [1] CRAN (R 4.0.2) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 4.0.2) ## stringi 1.5.3 2020-09-09 [1] CRAN (R 4.0.2) ## stringr 1.4.0 2019-02-10 [2] CRAN (R 4.0.0) ## testthat 2.3.2 2020-03-02 [2] CRAN (R 4.0.0) ## usethis 2.0.0 2020-12-10 [1] CRAN (R 4.0.2) ## withr 2.4.1 2021-01-26 [1] CRAN (R 4.0.2) ## xfun 0.23 2021-05-15 [1] CRAN (R 4.0.2) ## yaml 2.2.1 2020-02-01 [2] CRAN (R 4.0.0) ## ## [1] /Users/melissako/Library/R/4.0/library ## [2] /Library/Frameworks/R.framework/Versions/4.0/Resources/library why the hell we want others to use our code? Well I’ll tell you why - the general intellect think about this think about the next person coming along, or yourself in 3 months links on syllabus for more info all sorts of automated stuff you can do 4.8 Reproducibility and sharing think about this think about the next person coming along, or yourself in 3 months links on syllabus for more info all sorts of automated stuff you can do 4.9 Troubleshooting, getting help, dissecting problems You will have problems. How do you (1) get past these and (2) learn from them? What kinds of errors did we encounter in this class? How do we deal with these? 4.9.1 Places to look for help yourself - past notes, troubleshoot logically the people around you, research mentors Slack channel github/gitlab “Issues” page - search first the closed issues!!! StackOverflow - search first for similar problems!!! twitter (for fun problems) It helps to have a… 4.9.2 Minimum reproducible example video1 If you can’t find an easy answer, it is important to begin to approach the problem like you would a science problem. Reduce the problem, eliminate extraneous variables. Use or capture intermediate steps to identify where the issue is. Collect sessionInfo() and share it with folks. 4.10 Conclusion, other concepts Today we covered: loops to repeat code aspects of nice (re)usable code writing code modularly with functions finding and using packages writing an Rmarkdown report finding help and tackling a complex problem We hope you are better oriented and prepared to repeat your analyses to build a complete story, reproduce these larger analyses workflows, extend from your work to do more complicated workflows, and share your analyses with others in a well-organized but complete way. You can extend on these ideas. Here’s a couple of areas that might be useful: Workflow / pipeline tools These are automation tools to smartly run different chunks of analyses. This is really handy when parts of your workflow take a long time, and you usually don’t want to be re-running those, but you do want it to be able to run the whole thing automatically. You can use old-school shell-like tools such as “Make/Makefiles”, newfangled but complex tools like “Nextflow” or “snakemake”, or R-specific tooks like “targets”. Ask Darach if you want details, or read the paper↩ "],["appendix.html", "5 Appendix 5.1 Additional tutorials 5.2 More challenges 5.3 Figures ideas 5.4 Rmd example of code chunk 5.5 More example Rmds 5.6 How to edit this document 5.7 More links", " 5 Appendix Useful bits 5.1 Additional tutorials a list of tutorials 5.1.1 sub sub section 5.2 More challenges Challenge yourself Extra datasets ere 5.3 Figures ideas An interactive page showing different types of figures A R graph gallery 5.4 Rmd example of code chunk knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 5.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa 5.5 More example Rmds extraRmds/worksheet.Rmd 5.6 How to edit this document Here is a too-long video about how to edit this website. Each level 1 header is its own heading the left TOC 5.6.1 Setup Clone the repo locally git clone https://github.com/darachm/dll-r 5.6.2 Edit/work on it git pull so you’re current! Error with what is in docs/? Do git checkout docs/ to remove the edits to those, then pull again. Make or edit the files whose name starts with two digits and ends with Rmd, Like 01-day3.Rmd. Feel free to run that in Rstudio or whatever. To test the full site, sun ./_build.sh to build the entire site. ( Can Rstudio run this as a terminal ??? There may be another way to do this in Rstudio - I believe they develop the bookdown package? ) The entire site is in docs/ because that is what github wants. When done, add and commit your changes. git add 02-day4.Rmd # or whatever you changed git commit -m &quot;nice commit message of what you have done&quot; git checkout docs/ # this prevents errors from docs not matching what&#39;s published git pull # to make sure current git push # to push it up to github 5.6.3 Publishing onto the main page, so it’s hosted at the URL git pull # to make sure current # if there are conflicts, then run git checkout docs/ # this prevents errors from docs not matching what&#39;s published # if not, you can skip this step! ./_build.sh # builds the site in docs/ git add docs/* # adds the entire site to the repo git commit -m &quot;updated site&quot; git push # to push it up to github 5.7 More links Claus Wilke’s dataviz bookdown "]]
